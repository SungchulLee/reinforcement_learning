{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Large-Scale Reinforcement Learning\n",
    " \n",
    "Sungchul Lee  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# References\n",
    "\n",
    "- David Silver- Reinforcement Learning \n",
    "[6 Value Function Approximation](https://www.youtube.com/watch?v=UoPei5o4fps&index=6&list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT) \n",
    "[slide](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/FA.pdf)\n",
    "[local](http://localhost:8888/notebooks/Dropbox/Paper/Reinforcement Learning by David Silver 6.pdf) \n",
    "\n",
    "- David Silver\n",
    "[Tutorial: Deep Reinforcement Learning, ICML 2016](http://icml.cc/2016/tutorials/deep_rl_tutorial.pdf) \n",
    "[local](http://localhost:8888/notebooks/Dropbox/Paper/deep_rl_tutorial.pdf)\n",
    "\n",
    "- David Silver\n",
    "[Gradient Temporal Difference Networks](http://proceedings.mlr.press/v24/silver12a/silver12a.pdf) \n",
    "[local](http://localhost:8888/notebooks/Dropbox/Paper/silver12a.pdf)\n",
    "\n",
    "- 이웅원 [파이썬과 케라스로 배우는 강화학습](https://www.slideshare.net/WoongwonLee/ss-78783597?from_action=save)\n",
    "[local](http://localhost:8888/notebooks/Dropbox/Paper/random-170812084307.pdf)\n",
    "\n",
    "- 김정주\n",
    "[파이썬으로 나만의 강화학습 환경 만들기](https://www.youtube.com/watch?v=chVLag1NIAQ)\n",
    "\n",
    "- 김태훈\n",
    "[알아두면 쓸 데있는 신기한 강화학습](https://www.youtube.com/watch?v=NGGO0zdzhVQ)\n",
    "\n",
    "- 곽동현\n",
    "[Introduction of Deep Reinforcement Learning](https://www.youtube.com/watch?v=dw0sHzE1oAc)\n",
    "\n",
    "- 송호연\n",
    "[Deepmind StarCraft II AI](https://www.youtube.com/watch?v=eKA4EPpLCIU)\n",
    "\n",
    "- Nando de Freitas\n",
    "[Deep Learning: Practice and Trends, NIPS 2017 Tutorial](https://docs.google.com/presentation/d/e/2PACX-1vQMZsWfjjLLz_wi8iaMxHKawuTkdqeA3Gw00wy5dBHLhAkuLEvhB7k-4LcO5RQEVFzZXfS6ByABaRr4/pub?slide=id.p)\n",
    "\n",
    "- Hamid Maei\n",
    "[Gradient Temporal-Difference Learning Algorithms](http://ai2-s2-pdfs.s3.amazonaws.com/9494/639c7d4cc4aad0842c18a26562903ca0c6f8.pdf) \n",
    "[local](http://localhost:8888/notebooks/Dropbox/Paper/639c7d4cc4aad0842c18a26562903ca0c6f8.pdf) \n",
    "\n",
    "- Arthur Juliani\n",
    "[Simple Reinforcement Learning with Tensorflow Part 4: Deep Q-Networks and Beyond](https://medium.com/@awjuliani/simple-reinforcement-learning-with-tensorflow-part-4-deep-q-networks-and-beyond-8438a3e2b8df)\n",
    "\n",
    "- nalsil\n",
    "[DQN](https://github.com/nalsil/TensorFlow-Tutorials/tree/master/07%20-%20DQN)\n",
    "\n",
    "- Lee Young Moo\n",
    "[DQN](http://www.phrgcm.com/blog/2016/08/17/deep-q-network/)\n",
    "\n",
    "- [Asynchronous Methods for Deep Reinforcement Learning](https://arxiv.org/pdf/1602.01783v2.pdf)\n",
    "\n",
    "- [PR-005: Playing Atari with Deep Reinforcement Learning (NIPS 2013 Deep Learning Workshop)](https://www.youtube.com/watch?v=V7_cNTfm2i8&t=4s&list=PLlMkM4tgfjnJhhd4wn5aj8fVTYJwIpWkS&index=6)\n",
    "\n",
    "- Sung Kim - ReinforcementZeroToAll\n",
    "[Lecture 6 Q-Network](https://www.youtube.com/watch?v=w9GwqPx7LW8&list=PLlMkM4tgfjnKsCWav-Z2F-MMFRx-2gMGG&index=11) \n",
    "[실습 6-1 Q Network for Frozen Lake](https://www.youtube.com/watch?v=Fcmgl8ow2Uc&index=12&list=PLlMkM4tgfjnKsCWav-Z2F-MMFRx-2gMGG) \n",
    "[실습 6-2 Q Network for Cart Pole](https://www.youtube.com/watch?v=MF_Wllw9VKk&list=PLlMkM4tgfjnKsCWav-Z2F-MMFRx-2gMGG&index=13) \n",
    "[Lecture 7: DQN](https://www.youtube.com/watch?v=S1Y9eys2bdg&list=PLlMkM4tgfjnKsCWav-Z2F-MMFRx-2gMGG&index=14) \n",
    "[실습 7-1 DQN 1 (NIPS 2013)](https://www.youtube.com/watch?v=Fbf9YUyDFww&index=15&list=PLlMkM4tgfjnKsCWav-Z2F-MMFRx-2gMGG) \n",
    "[실습 7-2 DQN 2 (Nature 2015)](https://www.youtube.com/watch?v=ByB49iDMiZE&list=PLlMkM4tgfjnKsCWav-Z2F-MMFRx-2gMGG&index=16) \n",
    "[실습 7-3 DQN Cart Pole Demo (with Music)!](https://www.youtube.com/watch?v=TdA0APWRCx0&index=17&list=PLlMkM4tgfjnKsCWav-Z2F-MMFRx-2gMGG) \n",
    "[실습 7-4 DQN Simple Pacman exercise example (with Music)!](https://www.youtube.com/watch?v=SJQEWgkvBvo&index=18&list=PLlMkM4tgfjnKsCWav-Z2F-MMFRx-2gMGG) \n",
    "[실습 8-3 DQN vs Policy Gradient on Simple Pacman (with Music)!](https://www.youtube.com/watch?v=M8RfOCYIL8k&index=19&list=PLlMkM4tgfjnKsCWav-Z2F-MMFRx-2gMGG)\n",
    "\n",
    "- Hvass Laboratories \n",
    "[TensorFlow Tutorial #16 Reinforcement Learning](https://www.youtube.com/watch?v=Vz5l886eptw) [code](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/16_Reinforcement_Learning.ipynb)\n",
    "\n",
    "- Richard Sutton \n",
    "[Tutorial: Introduction to Reinforcement Learning with Function Approximation](https://www.youtube.com/watch?v=ggqnxyjaKe4)\n",
    "\n",
    "- Richard Sutton \n",
    "[The Long-term of AI & Temporal-Difference Learning](https://www.youtube.com/watch?v=EeMCEQa85tw)\n",
    "\n",
    "- Shane M. Conway \n",
    "[Introduction to Reinforcement Learning](https://www.youtube.com/watch?v=xa6AHMoND6E) \n",
    "\n",
    "- 송호연 -  강화학습으로 풀어보는 슈퍼마리오 \n",
    "[1](https://brunch.co.kr/@kakao-it/144) \n",
    "[2](https://brunch.co.kr/@kakao-it/161)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# How to run these slides yourself\n",
    "\n",
    "**Setup python environment**\n",
    "\n",
    "- [Install RISE for an interactive presentation viewer](https://github.com/damianavila/RISE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Large-Scale Reinforcement Learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"img/201701052205399322_t.jpg\" width=\"40%\" height=\"20%\"></div>\n",
    "\n",
    "http://image.ytn.co.kr/general/jpg/2017/0105/201701052205399322_t.jpg\n",
    "\n",
    "- DeepMind - AlphaGo Zero: Learning from scratch [youtube](https://www.youtube.com/watch?v=WXHFqTvfFSw&t=11s) [blog](https://deepmind.com/blog/alphago-zero-learning-scratch/)\n",
    "\n",
    "- Siraj Raval [Deep Q Learning for Video Games - The Math of Intelligence #9](https://www.youtube.com/watch?v=79pmNdyxEGo)\n",
    "\n",
    "- Two Minute Papers [New DeepMind AI Beats AlphaGo 100-0 | Two Minute Papers #201](https://www.youtube.com/watch?v=9xlSy9F5WtE)\n",
    "\n",
    "- Tim Kington [AlphaGo Zero](https://www.youtube.com/watch?v=XuzIqE2IshY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise\n",
    "\n",
    "How many states in Comupter Go?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"img/Screen Shot 2017-11-24 at 4.36.02 PM.png\" width=\"80%\" height=\"20%\"></div>\n",
    "\n",
    "https://en.wikipedia.org/wiki/AlphaGo_Zero\n",
    "\n",
    "- Go World Video [ALPHAGO ZERO new series ! Game 1 vs Alphago Master version](https://www.youtube.com/watch?v=-Wh4CfsWDyM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"img/Large-Scale Reinforcement Learning.png\" width=\"90%\" height=\"100%\"></div>\n",
    "\n",
    "http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/FA.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Function Approximation\n",
    "\n",
    "<div align=\"center\"><img src=\"img/Value Function Approximation.png\" width=\"60%\" height=\"20%\"></div>\n",
    "\n",
    "http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/FA.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Types of Function Approximation\n",
    "\n",
    "<div align=\"center\"><img src=\"img/Types of Value Function Approximation.png\" width=\"50%\" height=\"20%\"></div>\n",
    "\n",
    "http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/FA.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Value Function Approximation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Goal\n",
    "\n",
    "Find ${\\bf w}$ minimizing\n",
    "$$\n",
    "J({\\bf w})=\\mathbb{E}_\\pi\\left(v_\\pi(S)-v_{\\bf w}(S)\\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Stochastic gradient descent - Need oracle to tell $v_\\pi(S)$\n",
    "$$\\begin{array}{lllllll}\n",
    "\\mbox{GD}&\n",
    "\\Delta{\\bf w}\n",
    "&=&\\alpha&\\mathbb{E}_\\pi&\\left(v_\\pi(S)-v_{\\bf w}(S)\\right)\\nabla_{\\bf w}v_{\\bf w}(S)\\\\\n",
    "\\mbox{SGD}&\n",
    "\\Delta{\\bf w}\n",
    "&=&\\alpha&&\\left(v_\\pi(S_t)-v_{\\bf w}(S_t)\\right)\\nabla_{\\bf w}v_{\\bf w}(S_t)\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Incremental Method - No need oracle\n",
    "\n",
    "$$\\begin{array}{llllll}\n",
    "\\mbox{MC}&\\Delta{\\bf w}&=&\\alpha&\\left(G_t-v_{\\bf w}(S_t)\\right)&\\nabla_{\\bf w}v_{\\bf w}(S_t)\\\\\n",
    "\\mbox{TD}&\\Delta{\\bf w}&=&\\alpha&\\left(R_{t+1}+\\gamma v_{\\bf w}(S_{t+1}) -v_{\\bf w}(S_t)\\right)&\\nabla_{\\bf w}v_{\\bf w}(S_t)\\\\\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Incremental Method - Linear Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Represent state by a feature vector\n",
    "$$\n",
    "{\\bf x}(S)=\\left(\\begin{array}{c}\n",
    "{\\bf x}_1(S)\\\\\n",
    "\\vdots\\\\\n",
    "{\\bf x}_n(S)\n",
    "\\end{array}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Linear Value Function Approximation\n",
    "$$\n",
    "v_{\\bf w}(S)={\\bf x}(S)^T {\\bf w}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Incremental Prediction\n",
    "\n",
    "$$\\begin{array}{llllll}\n",
    "\\mbox{MC}&\\Delta{\\bf w}&=&\\alpha&\\left(G_t-v_{\\bf w}(S_t)\\right)&{\\bf x}(S_t)\\\\\n",
    "\\mbox{TD}&\\Delta{\\bf w}&=&\\alpha&\\left(R_{t+1}+\\gamma v_{\\bf w}(S_{t+1}) -v_{\\bf w}(S_t)\\right)&{\\bf x}(S_t)\\\\\n",
    "\\mbox{TD}(\\lambda)&\\Delta{\\bf w}&=&\\alpha&\\left(R_{t+1}+\\gamma v_{\\bf w}(S_{t+1}) -v_{\\bf w}(S_t)\\right)&(\\gamma\\lambda E_{t−1}+{\\bf x}(S_t))\\\\\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Action-Value Function Approximation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Goal\n",
    "\n",
    "Find ${\\bf w}$ minimizing\n",
    "$$\n",
    "J({\\bf w})=\\mathbb{E}_\\pi\\left(q_\\pi(S,A)-q_{\\bf w}(S,A)\\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### SGD - Need oracle to tell $q_\\pi(S,A)$\n",
    "$$\\begin{array}{llllllll}\n",
    "\\mbox{Gradient descent}&\n",
    "\\Delta{\\bf w}\n",
    "&=&\\alpha&\\mathbb{E}_\\pi&\\left(q_\\pi(S,A)-q_{\\bf w}(S,A)\\right)\\nabla_{\\bf w}q_{\\bf w}(S,A)\\\\\n",
    "\\mbox{Stochastic gradient descent}&\n",
    "\\Delta{\\bf w}\n",
    "&=&\\alpha&&\\left(q_\\pi(S_t,A_t)-q_{\\bf w}(S_t,A_t)\\right)\\nabla_{\\bf w}q_{\\bf w}(S_t,A_t)\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Incremental Method - No need oracle\n",
    "\n",
    "$$\\begin{array}{llllll}\n",
    "\\mbox{MC}&\\Delta{\\bf w}&=&\\alpha&\\left(G_t-q_{\\bf w}(S_t,A_t)\\right)&\\nabla_{\\bf w}q_{\\bf w}(S_t,A_t)\\\\\n",
    "\\mbox{TD}&\\Delta{\\bf w}&=&\\alpha&\\left(R_{t+1}+\\gamma q_{\\bf w}(S_{t+1},A_{t+1}) -q_{\\bf w}(S_t,A_t)\\right)&\\nabla_{\\bf w}q_{\\bf w}(S_t,A_t)\\\\\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Incremental Method - Linear Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Represent state by a feature vector\n",
    "$$\n",
    "{\\bf x}(S,A)=\\left(\\begin{array}{c}\n",
    "{\\bf x}_1(S,A)\\\\\n",
    "\\vdots\\\\\n",
    "{\\bf x}_n(S,A)\n",
    "\\end{array}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Linear Value Function Approximation\n",
    "$$\n",
    "q_{\\bf w}(S,A)={\\bf x}(S,A)^T {\\bf w}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Incremental Prediction\n",
    "\n",
    "$$\\begin{array}{llllll}\n",
    "\\mbox{MC}&\\Delta{\\bf w}&=&\\alpha&\\left(G_t-q_{\\bf w}(S_t,A_t)\\right)&{\\bf x}(S_t,A_t)\\\\\n",
    "\\mbox{TD}&\\Delta{\\bf w}&=&\\alpha&\\left(R_{t+1}+\\gamma q_{\\bf w}(S_{t+1},A_{t+1}) -q_{\\bf w}(S_t,A_t)\\right)&{\\bf x}(S_t,A_t)\\\\\n",
    "\\mbox{Q}&\\Delta{\\bf w}&=&\\alpha&\\left(R_{t+1}+\\gamma \\mbox{max}_{a'}q_{\\bf w}(S_{t+1},a') -q_{\\bf w}(S_t,A_t)\\right)&{\\bf x}(S_t,A_t)\\\\\n",
    "\\mbox{TD}(\\lambda)&\\Delta{\\bf w}&=&\\alpha&\\left(R_{t+1}+\\gamma q_{\\bf w}(S_{t+1},A_{t+1}) -q_{\\bf w}(S_t,A_t)\\right)&(\\gamma\\lambda E_{t−1}+{\\bf x}(S_t,A_t))\\\\\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DQN\n",
    "\n",
    "DQN paper: https://www.nature.com/articles/nature14236\n",
    "\n",
    "DQN source code: https://sites.google.com/a/deepmind.com/dqn/\n",
    "\n",
    "<div align=\"center\"><img src=\"img/DQN Nature.png\" width=\"30%\" height=\"20%\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"img/Deep Reinforcement Learning in Atari.png\" width=\"60%\" height=\"20%\"></div>\n",
    "\n",
    "http://icml.cc/2016/tutorials/deep_rl_tutorial.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"img/breakout.gif\" width=\"30%\" height=\"30%\"></div>\n",
    "\n",
    "http://ikuz.eu/wp-content/uploads/2015/02/breakout.gif\n",
    "\n",
    "DQN Breakout [DeepMind](https://www.youtube.com/watch?v=TmPfTpjtdgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"img/DQN in Atari.png\" width=\"60%\" height=\"20%\"></div>\n",
    "\n",
    "http://icml.cc/2016/tutorials/deep_rl_tutorial.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"img/DQN Results in Atari.png\" width=\"60%\" height=\"20%\"></div>\n",
    "\n",
    "http://icml.cc/2016/tutorials/deep_rl_tutorial.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"img/Experience Replay in Deep Q-Networks.png\" width=\"60%\" height=\"20%\"></div>\n",
    "\n",
    "http://icml.cc/2016/tutorials/deep_rl_tutorial.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why DQN works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Going from a single-layer network to a multi-layer convolutional network to approximate the Q function.\n",
    "\n",
    "- Implementing Experience Replay, which will allow our network to train itself using stored memories from it’s experience.\n",
    "\n",
    "- Utilizing a second “target” network, which we will use to compute target Q-values during our updates.\n",
    "\n",
    "https://medium.com/@awjuliani/simple-reinforcement-learning-with-tensorflow-part-4-deep-q-networks-and-beyond-8438a3e2b8df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DQN - numpy implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initial Burning Period\n",
      "Training Start\n",
      "Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[experience(state=9, action=2, reward=-0.02, next_state=5), experience(state=8, action=2, reward=-0.02, next_state=8), experience(state=4, action=0, reward=-0.02, next_state=4), experience(state=5, action=0, reward=-0.02, next_state=5), experience(state=0, action=2, reward=-0.02, next_state=0)]\n",
      "[experience(state=0, action=0, reward=-0.02, next_state=0), experience(state=0, action=1, reward=-0.02, next_state=1), experience(state=4, action=0, reward=-0.02, next_state=4), experience(state=0, action=2, reward=-0.02, next_state=1), experience(state=7, action=2, reward=-0.02, next_state=8)]\n",
      "[experience(state=9, action=3, reward=-0.02, next_state=9), experience(state=7, action=3, reward=-0.02, next_state=7), experience(state=2, action=1, reward=0.98, next_state=3), experience(state=10, action=2, reward=-1.02, next_state=6), experience(state=9, action=1, reward=-0.02, next_state=10)]\n",
      "[experience(state=1, action=1, reward=-0.02, next_state=1), experience(state=10, action=1, reward=-0.02, next_state=10), experience(state=1, action=0, reward=-0.02, next_state=1), experience(state=5, action=3, reward=-0.02, next_state=5), experience(state=7, action=1, reward=-0.02, next_state=8)]\n",
      "[experience(state=7, action=1, reward=-0.02, next_state=7), experience(state=10, action=1, reward=-0.02, next_state=10), experience(state=0, action=3, reward=-0.02, next_state=4), experience(state=0, action=3, reward=-0.02, next_state=4), experience(state=10, action=2, reward=-1.02, next_state=6)]\n",
      "[experience(state=7, action=1, reward=-0.02, next_state=8), experience(state=4, action=0, reward=-0.02, next_state=4), experience(state=4, action=1, reward=-0.02, next_state=4), experience(state=5, action=0, reward=-0.02, next_state=5), experience(state=2, action=2, reward=-0.02, next_state=1)]\n",
      "[experience(state=4, action=0, reward=-0.02, next_state=0), experience(state=4, action=0, reward=-0.02, next_state=0), experience(state=4, action=3, reward=-0.02, next_state=7), experience(state=4, action=2, reward=-0.02, next_state=0), experience(state=0, action=0, reward=-0.02, next_state=0)]\n",
      "[experience(state=8, action=2, reward=-0.02, next_state=8), experience(state=5, action=1, reward=-1.02, next_state=6), experience(state=7, action=2, reward=-0.02, next_state=8), experience(state=1, action=3, reward=-0.02, next_state=1), experience(state=0, action=3, reward=-0.02, next_state=0)]\n",
      "[experience(state=5, action=2, reward=-0.02, next_state=2), experience(state=7, action=2, reward=-0.02, next_state=4), experience(state=9, action=3, reward=-0.02, next_state=9), experience(state=4, action=2, reward=-0.02, next_state=0), experience(state=2, action=0, reward=-0.02, next_state=1)]\n",
      "[experience(state=7, action=3, reward=-0.02, next_state=7), experience(state=10, action=2, reward=-1.02, next_state=6), experience(state=8, action=3, reward=-0.02, next_state=8), experience(state=0, action=3, reward=-0.02, next_state=1), experience(state=0, action=2, reward=-0.02, next_state=0)]\n",
      "[experience(state=10, action=1, reward=-0.02, next_state=10), experience(state=9, action=3, reward=-0.02, next_state=8), experience(state=9, action=3, reward=-0.02, next_state=9), experience(state=9, action=1, reward=-0.02, next_state=10), experience(state=7, action=3, reward=-0.02, next_state=7)]\n",
      "[experience(state=4, action=1, reward=-0.02, next_state=7), experience(state=2, action=0, reward=-0.02, next_state=1), experience(state=1, action=0, reward=-0.02, next_state=0), experience(state=8, action=3, reward=-0.02, next_state=9), experience(state=5, action=3, reward=-0.02, next_state=9)]\n",
      "[experience(state=1, action=0, reward=-0.02, next_state=0), experience(state=0, action=0, reward=-0.02, next_state=0), experience(state=0, action=3, reward=-0.02, next_state=4), experience(state=1, action=0, reward=-0.02, next_state=1), experience(state=0, action=2, reward=-0.02, next_state=0)]\n",
      "[experience(state=7, action=0, reward=-0.02, next_state=7), experience(state=4, action=2, reward=-0.02, next_state=0), experience(state=7, action=0, reward=-0.02, next_state=4), experience(state=2, action=2, reward=-0.02, next_state=1), experience(state=0, action=3, reward=-0.02, next_state=0)]\n",
      "[experience(state=10, action=0, reward=-0.02, next_state=9), experience(state=9, action=3, reward=-0.02, next_state=9), experience(state=10, action=2, reward=-1.02, next_state=6), experience(state=1, action=2, reward=-0.02, next_state=1), experience(state=9, action=2, reward=-0.02, next_state=5)]\n",
      "[experience(state=8, action=1, reward=-0.02, next_state=9), experience(state=0, action=1, reward=-0.02, next_state=1), experience(state=8, action=3, reward=-0.02, next_state=8), experience(state=10, action=0, reward=-0.02, next_state=9), experience(state=2, action=2, reward=-0.02, next_state=2)]\n",
      "[experience(state=4, action=1, reward=-0.02, next_state=4), experience(state=10, action=0, reward=-0.02, next_state=9), experience(state=5, action=3, reward=-1.02, next_state=6), experience(state=2, action=3, reward=-0.02, next_state=5), experience(state=4, action=2, reward=-0.02, next_state=0)]\n",
      "[experience(state=2, action=3, reward=-0.02, next_state=5), experience(state=7, action=2, reward=-0.02, next_state=4), experience(state=2, action=0, reward=-0.02, next_state=1), experience(state=10, action=1, reward=-0.02, next_state=10), experience(state=7, action=0, reward=-0.02, next_state=7)]\n",
      "[experience(state=0, action=2, reward=-0.02, next_state=0), experience(state=8, action=0, reward=-0.02, next_state=8), experience(state=2, action=3, reward=-0.02, next_state=5), experience(state=1, action=3, reward=-0.02, next_state=1), experience(state=4, action=0, reward=-0.02, next_state=0)]\n",
      "[experience(state=8, action=1, reward=-0.02, next_state=9), experience(state=4, action=0, reward=-0.02, next_state=4), experience(state=7, action=0, reward=-0.02, next_state=7), experience(state=0, action=1, reward=-0.02, next_state=1), experience(state=8, action=0, reward=-0.02, next_state=7)]\n",
      "[experience(state=1, action=1, reward=-0.02, next_state=2), experience(state=4, action=1, reward=-0.02, next_state=4), experience(state=7, action=3, reward=-0.02, next_state=7), experience(state=7, action=1, reward=-0.02, next_state=8), experience(state=1, action=1, reward=-0.02, next_state=2)]\n",
      "[experience(state=0, action=0, reward=-0.02, next_state=0), experience(state=4, action=2, reward=-0.02, next_state=0), experience(state=7, action=1, reward=-0.02, next_state=4), experience(state=9, action=3, reward=-0.02, next_state=9), experience(state=8, action=2, reward=-0.02, next_state=8)]\n",
      "[experience(state=2, action=2, reward=-0.02, next_state=2), experience(state=1, action=2, reward=-0.02, next_state=1), experience(state=8, action=2, reward=-0.02, next_state=8), experience(state=8, action=3, reward=-0.02, next_state=8), experience(state=1, action=3, reward=-0.02, next_state=1)]\n",
      "[experience(state=10, action=0, reward=-0.02, next_state=9), experience(state=4, action=1, reward=-0.02, next_state=4), experience(state=1, action=0, reward=-0.02, next_state=0), experience(state=8, action=3, reward=-0.02, next_state=8), experience(state=4, action=0, reward=-0.02, next_state=4)]\n",
      "[experience(state=9, action=1, reward=-0.02, next_state=10), experience(state=2, action=2, reward=-0.02, next_state=2), experience(state=8, action=3, reward=-0.02, next_state=8), experience(state=8, action=0, reward=-0.02, next_state=7), experience(state=10, action=3, reward=-0.02, next_state=10)]\n",
      "[experience(state=8, action=3, reward=-0.02, next_state=8), experience(state=1, action=3, reward=-0.02, next_state=1), experience(state=9, action=3, reward=-0.02, next_state=9), experience(state=9, action=1, reward=-0.02, next_state=10), experience(state=10, action=1, reward=-0.02, next_state=10)]\n",
      "[experience(state=7, action=2, reward=-0.02, next_state=4), experience(state=5, action=1, reward=-1.02, next_state=6), experience(state=9, action=0, reward=-0.02, next_state=8), experience(state=1, action=2, reward=-0.02, next_state=1), experience(state=0, action=3, reward=-0.02, next_state=4)]\n",
      "[experience(state=4, action=1, reward=-0.02, next_state=7), experience(state=5, action=0, reward=-0.02, next_state=5), experience(state=4, action=0, reward=-0.02, next_state=4), experience(state=4, action=0, reward=-0.02, next_state=0), experience(state=7, action=1, reward=-0.02, next_state=8)]\n",
      "[experience(state=1, action=0, reward=-0.02, next_state=0), experience(state=4, action=1, reward=-0.02, next_state=7), experience(state=1, action=3, reward=-0.02, next_state=0), experience(state=4, action=2, reward=-0.02, next_state=0), experience(state=1, action=0, reward=-0.02, next_state=0)]\n",
      "[experience(state=0, action=0, reward=-0.02, next_state=0), experience(state=2, action=1, reward=0.98, next_state=3), experience(state=9, action=0, reward=-0.02, next_state=8), experience(state=8, action=2, reward=-0.02, next_state=8), experience(state=0, action=2, reward=-0.02, next_state=0)]\n",
      "[experience(state=4, action=2, reward=-0.02, next_state=0), experience(state=7, action=0, reward=-0.02, next_state=7), experience(state=10, action=1, reward=-0.02, next_state=10), experience(state=0, action=3, reward=-0.02, next_state=1), experience(state=7, action=0, reward=-0.02, next_state=7)]\n",
      "[experience(state=1, action=2, reward=-0.02, next_state=2), experience(state=0, action=0, reward=-0.02, next_state=0), experience(state=4, action=1, reward=-0.02, next_state=0), experience(state=8, action=3, reward=-0.02, next_state=8), experience(state=0, action=3, reward=-0.02, next_state=4)]\n",
      "[experience(state=0, action=3, reward=-0.02, next_state=4), experience(state=10, action=2, reward=-0.02, next_state=10), experience(state=5, action=0, reward=-0.02, next_state=5), experience(state=8, action=2, reward=-0.02, next_state=8), experience(state=9, action=1, reward=-0.02, next_state=10)]\n",
      "[experience(state=4, action=3, reward=-0.02, next_state=7), experience(state=9, action=2, reward=-0.02, next_state=5), experience(state=8, action=0, reward=-0.02, next_state=7), experience(state=1, action=2, reward=-0.02, next_state=2), experience(state=1, action=0, reward=-0.02, next_state=0)]\n",
      "[experience(state=7, action=0, reward=-0.02, next_state=4), experience(state=0, action=2, reward=-0.02, next_state=0), experience(state=10, action=2, reward=-1.02, next_state=6), experience(state=0, action=3, reward=-0.02, next_state=4), experience(state=4, action=3, reward=-0.02, next_state=7)]\n",
      "[experience(state=5, action=3, reward=-0.02, next_state=9), experience(state=7, action=3, reward=-0.02, next_state=7), experience(state=10, action=3, reward=-0.02, next_state=10), experience(state=7, action=0, reward=-0.02, next_state=7), experience(state=1, action=3, reward=-0.02, next_state=1)]\n",
      "[experience(state=1, action=2, reward=-0.02, next_state=2), experience(state=4, action=2, reward=-0.02, next_state=0), experience(state=9, action=2, reward=-0.02, next_state=5), experience(state=0, action=3, reward=-0.02, next_state=4), experience(state=10, action=1, reward=-0.02, next_state=10)]\n",
      "[experience(state=9, action=3, reward=-0.02, next_state=9), experience(state=4, action=3, reward=-0.02, next_state=7), experience(state=1, action=0, reward=-0.02, next_state=1), experience(state=8, action=1, reward=-0.02, next_state=9), experience(state=8, action=0, reward=-0.02, next_state=7)]\n",
      "[experience(state=1, action=3, reward=-0.02, next_state=1), experience(state=5, action=2, reward=-0.02, next_state=2), experience(state=5, action=3, reward=-0.02, next_state=9), experience(state=2, action=0, reward=-0.02, next_state=1), experience(state=2, action=1, reward=-0.02, next_state=5)]\n",
      "[experience(state=8, action=1, reward=-0.02, next_state=9), experience(state=1, action=3, reward=-0.02, next_state=1), experience(state=8, action=2, reward=-0.02, next_state=8), experience(state=0, action=3, reward=-0.02, next_state=1), experience(state=10, action=3, reward=-0.02, next_state=10)]\n",
      "[experience(state=9, action=3, reward=-0.02, next_state=9), experience(state=5, action=0, reward=-0.02, next_state=5), experience(state=4, action=2, reward=-0.02, next_state=0), experience(state=10, action=3, reward=-0.02, next_state=10), experience(state=9, action=0, reward=-0.02, next_state=8)]\n",
      "[experience(state=4, action=3, reward=-0.02, next_state=7), experience(state=2, action=0, reward=-0.02, next_state=1), experience(state=8, action=0, reward=-0.02, next_state=7), experience(state=5, action=1, reward=-1.02, next_state=6), experience(state=0, action=1, reward=-0.02, next_state=1)]\n",
      "[experience(state=1, action=3, reward=-0.02, next_state=0), experience(state=10, action=1, reward=-0.02, next_state=10), experience(state=4, action=3, reward=-0.02, next_state=7), experience(state=8, action=3, reward=-0.02, next_state=8), experience(state=2, action=3, reward=-0.02, next_state=5)]\n",
      "[experience(state=1, action=3, reward=-0.02, next_state=1), experience(state=2, action=2, reward=-0.02, next_state=2), experience(state=0, action=3, reward=-0.02, next_state=4), experience(state=8, action=2, reward=-0.02, next_state=8), experience(state=4, action=2, reward=-0.02, next_state=0)]\n",
      "[experience(state=4, action=2, reward=-0.02, next_state=0), experience(state=0, action=3, reward=-0.02, next_state=4), experience(state=4, action=1, reward=-0.02, next_state=4), experience(state=8, action=0, reward=-0.02, next_state=7), experience(state=0, action=1, reward=-0.02, next_state=1)]\n",
      "[experience(state=0, action=3, reward=-0.02, next_state=4), experience(state=0, action=0, reward=-0.02, next_state=0), experience(state=7, action=1, reward=-0.02, next_state=8), experience(state=0, action=0, reward=-0.02, next_state=0), experience(state=1, action=1, reward=-0.02, next_state=2)]\n",
      "[experience(state=10, action=3, reward=-0.02, next_state=10), experience(state=10, action=0, reward=-1.02, next_state=6), experience(state=9, action=3, reward=-0.02, next_state=9), experience(state=7, action=0, reward=-0.02, next_state=7), experience(state=9, action=0, reward=-0.02, next_state=8)]\n",
      "[experience(state=0, action=2, reward=-0.02, next_state=1), experience(state=7, action=1, reward=-0.02, next_state=4), experience(state=1, action=3, reward=-0.02, next_state=1), experience(state=7, action=3, reward=-0.02, next_state=7), experience(state=4, action=2, reward=-0.02, next_state=0)]\n",
      "[experience(state=9, action=0, reward=-0.02, next_state=8), experience(state=7, action=0, reward=-0.02, next_state=4), experience(state=1, action=0, reward=-0.02, next_state=0), experience(state=0, action=3, reward=-0.02, next_state=4), experience(state=4, action=1, reward=-0.02, next_state=4)]\n",
      "[experience(state=1, action=1, reward=-0.02, next_state=2), experience(state=7, action=1, reward=-0.02, next_state=7), experience(state=7, action=3, reward=-0.02, next_state=7), experience(state=1, action=3, reward=-0.02, next_state=1), experience(state=0, action=3, reward=-0.02, next_state=4)]\n",
      "[experience(state=10, action=1, reward=-0.02, next_state=10), experience(state=5, action=0, reward=-0.02, next_state=5), experience(state=0, action=3, reward=-0.02, next_state=1), experience(state=4, action=0, reward=-0.02, next_state=4), experience(state=1, action=2, reward=-0.02, next_state=1)]\n",
      "[experience(state=1, action=3, reward=-0.02, next_state=1), experience(state=2, action=1, reward=-0.02, next_state=2), experience(state=8, action=1, reward=-0.02, next_state=9), experience(state=10, action=1, reward=-0.02, next_state=10), experience(state=7, action=1, reward=-0.02, next_state=8)]\n",
      "[experience(state=10, action=2, reward=-1.02, next_state=6), experience(state=10, action=3, reward=-0.02, next_state=10), experience(state=4, action=3, reward=-0.02, next_state=4), experience(state=0, action=3, reward=-0.02, next_state=4), experience(state=7, action=2, reward=-0.02, next_state=7)]\n",
      "[experience(state=5, action=2, reward=-0.02, next_state=5), experience(state=1, action=3, reward=-0.02, next_state=1), experience(state=10, action=2, reward=-1.02, next_state=6), experience(state=8, action=3, reward=-0.02, next_state=9), experience(state=0, action=1, reward=-0.02, next_state=1)]\n",
      "[experience(state=1, action=3, reward=-0.02, next_state=1), experience(state=8, action=2, reward=-0.02, next_state=8), experience(state=1, action=1, reward=-0.02, next_state=1), experience(state=0, action=0, reward=-0.02, next_state=0), experience(state=8, action=1, reward=-0.02, next_state=9)]\n",
      "[experience(state=8, action=1, reward=-0.02, next_state=9), experience(state=10, action=0, reward=-0.02, next_state=9), experience(state=10, action=3, reward=-0.02, next_state=10), experience(state=4, action=1, reward=-0.02, next_state=4), experience(state=2, action=0, reward=-0.02, next_state=1)]\n",
      "[experience(state=4, action=2, reward=-0.02, next_state=4), experience(state=0, action=2, reward=-0.02, next_state=0), experience(state=1, action=2, reward=-0.02, next_state=1), experience(state=1, action=2, reward=-0.02, next_state=1), experience(state=7, action=0, reward=-0.02, next_state=7)]\n",
      "[experience(state=0, action=1, reward=-0.02, next_state=1), experience(state=2, action=1, reward=0.98, next_state=3), experience(state=2, action=2, reward=-0.02, next_state=2), experience(state=10, action=2, reward=-1.02, next_state=6), experience(state=10, action=0, reward=-0.02, next_state=9)]\n",
      "[experience(state=1, action=0, reward=-0.02, next_state=1), experience(state=0, action=1, reward=-0.02, next_state=1), experience(state=7, action=1, reward=-0.02, next_state=8), experience(state=10, action=1, reward=-0.02, next_state=10), experience(state=1, action=2, reward=-0.02, next_state=1)]\n",
      "[experience(state=5, action=2, reward=-0.02, next_state=2), experience(state=9, action=3, reward=-0.02, next_state=9), experience(state=7, action=3, reward=-0.02, next_state=7), experience(state=8, action=0, reward=-0.02, next_state=7), experience(state=7, action=1, reward=-0.02, next_state=8)]\n",
      "[experience(state=10, action=3, reward=-0.02, next_state=10), experience(state=2, action=0, reward=-0.02, next_state=2), experience(state=10, action=3, reward=-0.02, next_state=10), experience(state=4, action=2, reward=-0.02, next_state=0), experience(state=8, action=3, reward=-0.02, next_state=8)]\n",
      "[experience(state=4, action=3, reward=-0.02, next_state=7), experience(state=1, action=1, reward=-0.02, next_state=1), experience(state=1, action=3, reward=-0.02, next_state=1), experience(state=0, action=3, reward=-0.02, next_state=4), experience(state=1, action=3, reward=-0.02, next_state=1)]\n",
      "[experience(state=0, action=2, reward=-0.02, next_state=0), experience(state=2, action=2, reward=0.98, next_state=3), experience(state=8, action=2, reward=-0.02, next_state=9), experience(state=0, action=1, reward=-0.02, next_state=4), experience(state=5, action=0, reward=-0.02, next_state=9)]\n",
      "[experience(state=8, action=1, reward=-0.02, next_state=9), experience(state=8, action=2, reward=-0.02, next_state=8), experience(state=0, action=3, reward=-0.02, next_state=4), experience(state=2, action=0, reward=-0.02, next_state=1), experience(state=7, action=2, reward=-0.02, next_state=4)]\n",
      "[experience(state=4, action=2, reward=-0.02, next_state=0), experience(state=9, action=2, reward=-0.02, next_state=5), experience(state=9, action=1, reward=-0.02, next_state=10), experience(state=2, action=0, reward=-0.02, next_state=1), experience(state=2, action=2, reward=-0.02, next_state=2)]\n",
      "[experience(state=7, action=1, reward=-0.02, next_state=8), experience(state=5, action=2, reward=-0.02, next_state=2), experience(state=9, action=1, reward=-0.02, next_state=10), experience(state=2, action=2, reward=0.98, next_state=3), experience(state=1, action=3, reward=-0.02, next_state=1)]\n",
      "[experience(state=1, action=0, reward=-0.02, next_state=0), experience(state=0, action=3, reward=-0.02, next_state=4), experience(state=9, action=1, reward=-0.02, next_state=10), experience(state=5, action=2, reward=-0.02, next_state=2), experience(state=0, action=3, reward=-0.02, next_state=1)]\n",
      "[experience(state=8, action=0, reward=-0.02, next_state=8), experience(state=0, action=1, reward=-0.02, next_state=1), experience(state=8, action=3, reward=-0.02, next_state=8), experience(state=9, action=1, reward=-0.02, next_state=10), experience(state=9, action=1, reward=-0.02, next_state=10)]\n",
      "[experience(state=4, action=1, reward=-0.02, next_state=4), experience(state=2, action=0, reward=-0.02, next_state=1), experience(state=7, action=2, reward=-0.02, next_state=4), experience(state=4, action=2, reward=-0.02, next_state=0), experience(state=1, action=3, reward=-0.02, next_state=1)]\n",
      "[experience(state=5, action=0, reward=-0.02, next_state=2), experience(state=8, action=3, reward=-0.02, next_state=8), experience(state=7, action=2, reward=-0.02, next_state=7), experience(state=4, action=3, reward=-0.02, next_state=7), experience(state=0, action=2, reward=-0.02, next_state=0)]\n",
      "[experience(state=5, action=1, reward=-0.02, next_state=2), experience(state=7, action=3, reward=-0.02, next_state=7), experience(state=2, action=2, reward=-0.02, next_state=2), experience(state=8, action=3, reward=-0.02, next_state=8), experience(state=2, action=0, reward=-0.02, next_state=1)]\n",
      "[experience(state=0, action=1, reward=-0.02, next_state=0), experience(state=7, action=1, reward=-0.02, next_state=8), experience(state=0, action=3, reward=-0.02, next_state=4), experience(state=7, action=0, reward=-0.02, next_state=7), experience(state=9, action=1, reward=-0.02, next_state=10)]\n",
      "[experience(state=1, action=0, reward=-0.02, next_state=0), experience(state=7, action=1, reward=-0.02, next_state=8), experience(state=0, action=1, reward=-0.02, next_state=1), experience(state=8, action=1, reward=-0.02, next_state=9), experience(state=1, action=2, reward=-0.02, next_state=1)]\n",
      "[experience(state=0, action=3, reward=-0.02, next_state=1), experience(state=8, action=1, reward=-0.02, next_state=9), experience(state=5, action=1, reward=-1.02, next_state=6), experience(state=10, action=3, reward=-0.02, next_state=10), experience(state=8, action=1, reward=-0.02, next_state=9)]\n",
      "[experience(state=4, action=3, reward=-0.02, next_state=7), experience(state=1, action=1, reward=-0.02, next_state=1), experience(state=9, action=2, reward=-0.02, next_state=5), experience(state=1, action=1, reward=-0.02, next_state=2), experience(state=0, action=1, reward=-0.02, next_state=4)]\n",
      "[experience(state=2, action=3, reward=-0.02, next_state=5), experience(state=8, action=2, reward=-0.02, next_state=8), experience(state=0, action=1, reward=-0.02, next_state=4), experience(state=8, action=3, reward=-0.02, next_state=9), experience(state=2, action=1, reward=0.98, next_state=3)]\n",
      "[experience(state=9, action=2, reward=-0.02, next_state=5), experience(state=4, action=1, reward=-0.02, next_state=4), experience(state=10, action=1, reward=-0.02, next_state=10), experience(state=8, action=0, reward=-0.02, next_state=7), experience(state=7, action=3, reward=-0.02, next_state=7)]\n",
      "[experience(state=2, action=3, reward=-0.02, next_state=5), experience(state=5, action=2, reward=-0.02, next_state=2), experience(state=1, action=1, reward=-0.02, next_state=2), experience(state=4, action=3, reward=-0.02, next_state=7), experience(state=1, action=3, reward=-0.02, next_state=1)]\n",
      "[experience(state=1, action=1, reward=-0.02, next_state=1), experience(state=1, action=1, reward=-0.02, next_state=2), experience(state=4, action=2, reward=-0.02, next_state=0), experience(state=1, action=3, reward=-0.02, next_state=2), experience(state=2, action=1, reward=0.98, next_state=3)]\n",
      "[experience(state=1, action=3, reward=-0.02, next_state=1), experience(state=9, action=1, reward=-0.02, next_state=9), experience(state=7, action=0, reward=-0.02, next_state=7), experience(state=0, action=3, reward=-0.02, next_state=4), experience(state=7, action=2, reward=-0.02, next_state=4)]\n",
      "[experience(state=7, action=1, reward=-0.02, next_state=8), experience(state=4, action=2, reward=-0.02, next_state=0), experience(state=9, action=0, reward=-0.02, next_state=8), experience(state=7, action=0, reward=-0.02, next_state=7), experience(state=7, action=0, reward=-0.02, next_state=7)]\n"
     ]
    }
   ],
   "source": [
    "# DQN - numpy implementation\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from collections import deque, namedtuple\n",
    "import logging\n",
    "\n",
    "from dqn_env import ENVIRONMENT\n",
    "from dqn_ops import one_hot_encode\n",
    "\n",
    "# this line is not needed in py file\n",
    "%matplotlib inline\n",
    "# this line is not needed in py file\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(message)s')\n",
    "\n",
    "\"\"\" Hyper Parameters \"\"\"\n",
    "gamma = 0.99\n",
    "max_episodes = 1 #10000\n",
    "memory_size = 1000\n",
    "num_burning_episode = 100\n",
    "batch_size = 5 #32\n",
    "copy_period = 100\n",
    "test_period = 100\n",
    "epsilon_test = 0.00\n",
    "\n",
    "\"\"\" Environment \"\"\"\n",
    "env = ENVIRONMENT()\n",
    "exp = namedtuple('experience', ['state', 'action', 'reward', 'next_state'])\n",
    "\n",
    "\"\"\" Q-net and target Q-net \"\"\"\n",
    "W = np.random.uniform(0.0, 1.0, [env.num_states, env.num_actions])\n",
    "W_target = deepcopy(W)\n",
    "\n",
    "\"\"\" Replay Memory\"\"\"\n",
    "replay_memory = deque(maxlen=memory_size)\n",
    "\n",
    "\"\"\" Burning Period \"\"\"\n",
    "logging.info('Initial Burning Period')\n",
    "for _ in range(num_burning_episode):\n",
    "    env.current_state, env.done = env.reset()\n",
    "    \n",
    "    while not env.done:\n",
    "        # we take random action so that\n",
    "        # samples are less correlated\n",
    "        # initially these samples will fill the replay memory\n",
    "        action = env.random_action() # this is random action\n",
    "        env.reward, next_state, env.done, _, _ = env.step(action)\n",
    "        \n",
    "        sample = exp(state=env.current_state, \\\n",
    "                     action=action, \\\n",
    "                     reward=env.reward, \\\n",
    "                     next_state=next_state)\n",
    "        replay_memory.append(sample)\n",
    "\n",
    "        env.current_state = next_state\n",
    "\n",
    "\"\"\" Training \"\"\"\n",
    "logging.info('Training Start')\n",
    "train_step = 0\n",
    "cum_return_test = []\n",
    "step_history = []\n",
    "for episode_num in range(max_episodes):\n",
    "    # Reset Environment and Reset Cum. Reward\n",
    "    env.current_state, env.done = env.reset()\n",
    "\n",
    "    learning_rate = 1. / ((episode_num * 0.1) + 1.)\n",
    "    epsilon = 1. / ((episode_num * 0.1) + 1.)\n",
    "\n",
    "    while not env.done:\n",
    "        \n",
    "        # Action Selection\n",
    "        if np.random.uniform(0.,1.) > epsilon:\n",
    "            state_one_hot = one_hot_encode([env.current_state], env.num_states) # rank 2\n",
    "            action = np.argmax(state_one_hot @ W)\n",
    "        else:\n",
    "            action = env.random_action() # random action\n",
    "            \n",
    "        env.reward, next_state, env.done, _, _ = env.step(action)\n",
    "\n",
    "        sample = exp(state=env.current_state, \\\n",
    "                     action=action, \\\n",
    "                     reward=env.reward, \\\n",
    "                     next_state=next_state)\n",
    "        replay_memory.append(sample)\n",
    "        \n",
    "        env.current_state = next_state\n",
    "\n",
    "        # Sample scenarios from replay-memory.\n",
    "        samples = random.sample(replay_memory, batch_size)\n",
    "        \n",
    "        print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n",
      "Initial Burning Period\n",
      "Training Start\n",
      "Episode  100\n",
      "Episode  200\n",
      "Episode  300\n",
      "Episode  400\n",
      "Episode  500\n",
      "Episode  600\n",
      "Episode  700\n",
      "Episode  800\n",
      "Episode  900\n",
      "Episode  1000\n",
      "Episode  1100\n",
      "Episode  1200\n",
      "Episode  1300\n",
      "Episode  1400\n",
      "Episode  1500\n",
      "Episode  1600\n",
      "Episode  1700\n",
      "Episode  1800\n",
      "Episode  1900\n",
      "Episode  2000\n",
      "Episode  2100\n",
      "Episode  2200\n",
      "Episode  2300\n",
      "Episode  2400\n",
      "Episode  2500\n",
      "Episode  2600\n",
      "Episode  2700\n",
      "Episode  2800\n",
      "Episode  2900\n",
      "Episode  3000\n",
      "Episode  3100\n",
      "Episode  3200\n",
      "Episode  3300\n",
      "Episode  3400\n",
      "Episode  3500\n",
      "Episode  3600\n",
      "Episode  3700\n",
      "Episode  3800\n",
      "Episode  3900\n",
      "Episode  4000\n",
      "Episode  4100\n",
      "Episode  4200\n",
      "Episode  4300\n",
      "Episode  4400\n",
      "Episode  4500\n",
      "Episode  4600\n",
      "Episode  4700\n",
      "Episode  4800\n",
      "Episode  4900\n",
      "Episode  5000\n",
      "Episode  5100\n",
      "Episode  5200\n",
      "Episode  5300\n",
      "Episode  5400\n",
      "Episode  5500\n",
      "Episode  5600\n",
      "Episode  5700\n",
      "Episode  5800\n",
      "Episode  5900\n",
      "Episode  6000\n",
      "Episode  6100\n",
      "Episode  6200\n",
      "Episode  6300\n",
      "Episode  6400\n",
      "Episode  6500\n",
      "Episode  6600\n",
      "Episode  6700\n",
      "Episode  6800\n",
      "Episode  6900\n",
      "Episode  7000\n",
      "Episode  7100\n",
      "Episode  7200\n",
      "Episode  7300\n",
      "Episode  7400\n",
      "Episode  7500\n",
      "Episode  7600\n",
      "Episode  7700\n",
      "Episode  7800\n",
      "Episode  7900\n",
      "Episode  8000\n",
      "Episode  8100\n",
      "Episode  8200\n",
      "Episode  8300\n",
      "Episode  8400\n",
      "Episode  8500\n",
      "Episode  8600\n",
      "Episode  8700\n",
      "Episode  8800\n",
      "Episode  8900\n",
      "Episode  9000\n",
      "Episode  9100\n",
      "Episode  9200\n",
      "Episode  9300\n",
      "Episode  9400\n",
      "Episode  9500\n",
      "Episode  9600\n",
      "Episode  9700\n",
      "Episode  9800\n",
      "Episode  9900\n",
      "Episode  10000\n",
      "update_title_pos\n",
      "update_title_pos\n",
      "update_title_pos\n",
      "update_title_pos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9918\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_title_pos\n",
      "update_title_pos\n",
      "update_title_pos\n",
      "update_title_pos\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DQN - numpy implementation\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from collections import deque, namedtuple\n",
    "import logging\n",
    "\n",
    "from dqn_env import ENVIRONMENT\n",
    "from dqn_ops import one_hot_encode\n",
    "\n",
    "# this line is not needed in py file\n",
    "%matplotlib inline\n",
    "# this line is not needed in py file\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(message)s')\n",
    "\n",
    "\"\"\" Hyper Parameters \"\"\"\n",
    "gamma = 0.99\n",
    "max_episodes = 10000\n",
    "memory_size = 1000\n",
    "num_burning_episode = 100\n",
    "batch_size = 32\n",
    "copy_period = 100\n",
    "test_period = 100\n",
    "epsilon_test = 0.00\n",
    "\n",
    "\"\"\" Environment \"\"\"\n",
    "env = ENVIRONMENT()\n",
    "exp = namedtuple('experience', ['state', 'action', 'reward', 'next_state'])\n",
    "\n",
    "\"\"\" Q-net and target Q-net \"\"\"\n",
    "W = np.random.uniform(0.0, 1.0, [env.num_states, env.num_actions])\n",
    "W_target = deepcopy(W)\n",
    "\n",
    "\"\"\" Replay Memory\"\"\"\n",
    "replay_memory = deque(maxlen=memory_size)\n",
    "\n",
    "\"\"\" Burning Period \"\"\"\n",
    "logging.info('Initial Burning Period')\n",
    "for _ in range(num_burning_episode):\n",
    "    env.current_state, env.done = env.reset()\n",
    "    \n",
    "    while not env.done:\n",
    "        # we take random action so that\n",
    "        # samples are less correlated\n",
    "        # initially these samples will fill the replay memory\n",
    "        action = env.random_action() # this is random action\n",
    "        env.reward, next_state, env.done, _, _ = env.step(action)\n",
    "        \n",
    "        sample = exp(state=env.current_state, \\\n",
    "                     action=action, \\\n",
    "                     reward=env.reward, \\\n",
    "                     next_state=next_state)\n",
    "        replay_memory.append(sample)\n",
    "\n",
    "        env.current_state = next_state\n",
    "\n",
    "\"\"\" Training \"\"\"\n",
    "logging.info('Training Start')\n",
    "train_step = 0\n",
    "cum_return_test = []\n",
    "step_history = []\n",
    "for episode_num in range(max_episodes):\n",
    "    # Reset Environment and Reset Cum. Reward\n",
    "    env.current_state, env.done = env.reset()\n",
    "\n",
    "    learning_rate = 1. / ((episode_num * 0.1) + 1.)\n",
    "    epsilon = 1. / ((episode_num * 0.1) + 1.)\n",
    "\n",
    "    while not env.done:\n",
    "        \n",
    "        # Action Selection\n",
    "        if np.random.uniform(0.,1.) > epsilon:\n",
    "            state_one_hot = one_hot_encode([env.current_state], env.num_states) # rank 2\n",
    "            action = np.argmax(state_one_hot @ W)\n",
    "        else:\n",
    "            action = env.random_action() # random action\n",
    "            \n",
    "        env.reward, next_state, env.done, _, _ = env.step(action)\n",
    "\n",
    "        sample = exp(state=env.current_state, \\\n",
    "                     action=action, \\\n",
    "                     reward=env.reward, \\\n",
    "                     next_state=next_state)\n",
    "        replay_memory.append(sample)\n",
    "        \n",
    "        env.current_state = next_state\n",
    "\n",
    "        # Sample scenarios from replay-memory.\n",
    "        samples = random.sample(replay_memory, batch_size)\n",
    "\n",
    "        states_ = [sample.state for sample in samples]\n",
    "        actions_ = [sample.action for sample in samples]\n",
    "        rewards_ = [sample.reward for sample in samples]\n",
    "        next_states_ = [sample.next_state for sample in samples]\n",
    "\n",
    "        states = one_hot_encode(states_, env.num_states) # rank 2\n",
    "        actions = one_hot_encode(actions_, env.num_actions) # rank 2\n",
    "        rewards = np.reshape(np.array(rewards_, dtype=np.float32), (-1, 1))\n",
    "        next_states = one_hot_encode(next_states_, env.num_states) # rank 2\n",
    "\n",
    "        # Make target for Q-net.\n",
    "        q_target_max = np.amax(np.matmul(next_states, W_target), axis=1, keepdims=True)\n",
    "        targets = rewards + gamma * q_target_max # (32,1)\n",
    "\n",
    "        # Weight Update\n",
    "        q_val = np.sum(np.matmul(states, W) * actions, axis=1, keepdims=True) # (32,1)\n",
    "        gradient = np.reshape((targets - q_val), [-1]) # negative gradient up to constant multiplication \n",
    "        # you have to choose one of the following three update rule\n",
    "        if 0:\n",
    "            # this implementation is wrong\n",
    "            W[states_, actions_] += learning_rate * gradient\n",
    "        elif 0:\n",
    "            # this implementation is correct\n",
    "            # but, not good for reading\n",
    "            for i in range(batch_size):\n",
    "                W[states_[i], actions_[i]] += learning_rate * gradient[i]\n",
    "        elif 1:\n",
    "            dW = np.zeros(W.shape)\n",
    "            for i in range(batch_size):\n",
    "                dW[states_[i], actions_[i]] += gradient[i]\n",
    "            W += learning_rate * dW\n",
    "\n",
    "        train_step += 1 # count gradient descent update\n",
    "\n",
    "        # Network Synchronization\n",
    "        if train_step % copy_period == 0:\n",
    "            W_target = deepcopy(W)\n",
    "\n",
    "        # Terminal of Scenario.\n",
    "        if env.done:\n",
    "            if env.current_state == env.win_state:\n",
    "                step_history.append(1)\n",
    "            if env.current_state == env.lose_state:\n",
    "                step_history.append(0)\n",
    "            break\n",
    "\n",
    "    if (episode_num + 1) % 100 == 0:\n",
    "        logging.info('Episode  %d' % (episode_num+1))\n",
    "\n",
    "    \"\"\" Test \"\"\"\n",
    "    if episode_num % test_period == 0:\n",
    "        env.current_state, env.done = env.reset()\n",
    "        cum_rwd = 0.0\n",
    "\n",
    "        while not env.done:\n",
    "            \n",
    "            # Action Selection\n",
    "            if np.random.uniform(0.,1.) > epsilon_test:\n",
    "                state_one_hot = one_hot_encode([env.current_state], env.num_states) # rank 2\n",
    "                action = np.argmax(state_one_hot @ W)\n",
    "            else:\n",
    "                action = env.random_action()\n",
    "\n",
    "            env.reward, next_state, env.done, _, _ = env.step(action)\n",
    "            cum_rwd += env.reward\n",
    "            \n",
    "            if cum_rwd < -10.:\n",
    "                break\n",
    "\n",
    "            env.current_state = next_state\n",
    "\n",
    "        cum_return_test.append(cum_rwd)\n",
    "\n",
    "fig = plt.figure(1)\n",
    "history = np.cumsum(step_history) / (np.arange(max_episodes) + 1)\n",
    "print(history[-1])\n",
    "plt.plot(history)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(2)\n",
    "plt.plot(np.arange(len(cum_return_test)) * test_period, cum_return_test)\n",
    "plt.xlabel('episode.')\n",
    "plt.ylabel('cum. reward')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 3. 3.]\n",
      "[[0.  1.1]\n",
      " [2.  3.2]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "W = np.array([[0., 1.],\n",
    "              [2., 3.]])\n",
    "\n",
    "states = [0,1,1]\n",
    "actions = [1,1,1]\n",
    "    \n",
    "print(W[states,actions])\n",
    "\n",
    "lr = 1.\n",
    "delta = np.array([0.1,-0.1,0.2])\n",
    "\n",
    "if 0:\n",
    "    W[states,actions] += lr*delta\n",
    "elif 0:\n",
    "    for i in range(3):\n",
    "        W[states[i],actions[i]] += lr*delta[i]\n",
    "elif 1:\n",
    "    dW = np.zeros(W.shape)\n",
    "    for i in range(len(states)):\n",
    "        dW[states[i], actions[i]] += delta[i]\n",
    "    W += lr * dW\n",
    "    \n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DQN- tensorflow implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initial Burning Period\n",
      "Training Start\n",
      "Episode  100\n",
      "Episode  200\n",
      "Episode  300\n",
      "Episode  400\n",
      "Episode  500\n",
      "Episode  600\n",
      "Episode  700\n",
      "Episode  800\n",
      "Episode  900\n",
      "Episode  1000\n",
      "Episode  1100\n",
      "Episode  1200\n",
      "Episode  1300\n",
      "Episode  1400\n",
      "Episode  1500\n",
      "Episode  1600\n",
      "Episode  1700\n",
      "Episode  1800\n",
      "Episode  1900\n",
      "Episode  2000\n",
      "Episode  2100\n",
      "Episode  2200\n",
      "Episode  2300\n",
      "Episode  2400\n",
      "Episode  2500\n",
      "Episode  2600\n",
      "Episode  2700\n",
      "Episode  2800\n",
      "Episode  2900\n",
      "Episode  3000\n",
      "Episode  3100\n",
      "Episode  3200\n",
      "Episode  3300\n",
      "Episode  3400\n",
      "Episode  3500\n",
      "Episode  3600\n",
      "Episode  3700\n",
      "Episode  3800\n",
      "Episode  3900\n",
      "Episode  4000\n",
      "Episode  4100\n",
      "Episode  4200\n",
      "Episode  4300\n",
      "Episode  4400\n",
      "Episode  4500\n",
      "Episode  4600\n",
      "Episode  4700\n",
      "Episode  4800\n",
      "Episode  4900\n",
      "Episode  5000\n",
      "Episode  5100\n",
      "Episode  5200\n",
      "Episode  5300\n",
      "Episode  5400\n",
      "Episode  5500\n",
      "Episode  5600\n",
      "Episode  5700\n",
      "Episode  5800\n",
      "Episode  5900\n",
      "Episode  6000\n",
      "Episode  6100\n",
      "Episode  6200\n",
      "Episode  6300\n",
      "Episode  6400\n",
      "Episode  6500\n",
      "Episode  6600\n",
      "Episode  6700\n",
      "Episode  6800\n",
      "Episode  6900\n",
      "Episode  7000\n",
      "Episode  7100\n",
      "Episode  7200\n",
      "Episode  7300\n",
      "Episode  7400\n",
      "Episode  7500\n",
      "Episode  7600\n",
      "Episode  7700\n",
      "Episode  7800\n",
      "Episode  7900\n",
      "Episode  8000\n",
      "Episode  8100\n",
      "Episode  8200\n",
      "Episode  8300\n",
      "Episode  8400\n",
      "Episode  8500\n",
      "Episode  8600\n",
      "Episode  8700\n",
      "Episode  8800\n",
      "Episode  8900\n",
      "Episode  9000\n",
      "Episode  9100\n",
      "Episode  9200\n",
      "Episode  9300\n",
      "Episode  9400\n",
      "Episode  9500\n",
      "Episode  9600\n",
      "Episode  9700\n",
      "Episode  9800\n",
      "Episode  9900\n",
      "Episode  10000\n",
      "Episode  10100\n",
      "Episode  10200\n",
      "Episode  10300\n",
      "Episode  10400\n",
      "Episode  10500\n",
      "Episode  10600\n",
      "Episode  10700\n",
      "Episode  10800\n",
      "Episode  10900\n",
      "Episode  11000\n",
      "Episode  11100\n",
      "Episode  11200\n",
      "Episode  11300\n",
      "Episode  11400\n",
      "Episode  11500\n",
      "Episode  11600\n",
      "Episode  11700\n",
      "Episode  11800\n",
      "Episode  11900\n",
      "Episode  12000\n",
      "Episode  12100\n",
      "Episode  12200\n",
      "Episode  12300\n",
      "Episode  12400\n",
      "Episode  12500\n",
      "Episode  12600\n",
      "Episode  12700\n",
      "Episode  12800\n",
      "Episode  12900\n",
      "Episode  13000\n",
      "Episode  13100\n",
      "Episode  13200\n",
      "Episode  13300\n",
      "Episode  13400\n",
      "Episode  13500\n",
      "Episode  13600\n",
      "Episode  13700\n",
      "Episode  13800\n",
      "Episode  13900\n",
      "Episode  14000\n",
      "Episode  14100\n",
      "Episode  14200\n",
      "Episode  14300\n",
      "Episode  14400\n",
      "Episode  14500\n",
      "Episode  14600\n",
      "Episode  14700\n",
      "Episode  14800\n",
      "Episode  14900\n",
      "Episode  15000\n",
      "Episode  15100\n",
      "Episode  15200\n",
      "Episode  15300\n",
      "Episode  15400\n",
      "Episode  15500\n",
      "Episode  15600\n",
      "Episode  15700\n",
      "Episode  15800\n",
      "Episode  15900\n",
      "Episode  16000\n",
      "Episode  16100\n",
      "Episode  16200\n",
      "Episode  16300\n",
      "Episode  16400\n",
      "Episode  16500\n",
      "Episode  16600\n",
      "Episode  16700\n",
      "Episode  16800\n",
      "Episode  16900\n",
      "Episode  17000\n",
      "Episode  17100\n",
      "Episode  17200\n",
      "Episode  17300\n",
      "Episode  17400\n",
      "Episode  17500\n",
      "Episode  17600\n",
      "Episode  17700\n",
      "Episode  17800\n",
      "Episode  17900\n",
      "Episode  18000\n",
      "Episode  18100\n",
      "Episode  18200\n",
      "Episode  18300\n",
      "Episode  18400\n",
      "Episode  18500\n",
      "Episode  18600\n",
      "Episode  18700\n",
      "Episode  18800\n",
      "Episode  18900\n",
      "Episode  19000\n",
      "Episode  19100\n",
      "Episode  19200\n",
      "Episode  19300\n",
      "Episode  19400\n",
      "Episode  19500\n",
      "Episode  19600\n",
      "Episode  19700\n",
      "Episode  19800\n",
      "Episode  19900\n",
      "Episode  20000\n",
      "update_title_pos\n",
      "findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/anaconda3/lib/python3.5/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.\n",
      "update_title_pos\n",
      "update_title_pos\n",
      "update_title_pos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99485\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_title_pos\n",
      "update_title_pos\n",
      "update_title_pos\n",
      "update_title_pos\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "# DQN - tensorflow implementation\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import threading\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "from dqn_env import ENVIRONMENT\n",
    "from dqn_ops import one_hot_encode, variable_copy \n",
    "from dqn_q_net import QNet\n",
    "\n",
    "# this line is not needed in py file\n",
    "%matplotlib inline\n",
    "# this line is not needed in py file\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_random_seed(0)\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(message)s')\n",
    "\n",
    "\"\"\" Hyper Parameters \"\"\"\n",
    "gamma = 0.99\n",
    "max_episodes = 20000\n",
    "epsilon = 0.10\n",
    "memory_size = 1000\n",
    "num_burning_episode = 100\n",
    "batch_size = 32\n",
    "copy_period = 100\n",
    "test_period = 100\n",
    "epsilon_test = 0.00\n",
    "\n",
    "\"\"\" Environment \"\"\"\n",
    "env = ENVIRONMENT()\n",
    "exp = namedtuple('experience', ['state', 'action', 'reward', 'next_state', 'done'])\n",
    "\n",
    "\" Train-Queue \"\n",
    "train_q = tf.FIFOQueue(capacity=100,\n",
    "                       dtypes=[tf.float32, tf.int32, tf.float32, tf.float32, tf.bool],\n",
    "                       shapes=[env.num_states, [], 1, env.num_states, 1],\n",
    "                       name='train_queue')\n",
    "\n",
    "\" Inputs Placeholder \"\n",
    "state_holder = tf.placeholder(tf.float32, [None, env.num_states], 'state_holder')\n",
    "action_holder = tf.placeholder(tf.int32, [None], 'action_holder')\n",
    "reward_holder = tf.placeholder(tf.float32, [None, 1], 'reward_holder')\n",
    "next_state_holder = tf.placeholder(tf.float32, [None, env.num_states], 'next_state_holder')\n",
    "done_holder = tf.placeholder(tf.bool, [None, 1], 'state_holder')\n",
    "lr_rate = tf.placeholder(dtype=tf.float32, shape=[], name='lr_rate')\n",
    "\n",
    "state_holder_explore = tf.placeholder(tf.float32, [None, env.num_states], \\\n",
    "                                      'state_holder_explore')\n",
    "\n",
    "\" Queue Ops \"\n",
    "enqueue_op = train_q.enqueue_many([state_holder, \\\n",
    "                                   action_holder, \\\n",
    "                                   reward_holder, \\\n",
    "                                   next_state_holder, \\\n",
    "                                   done_holder])\n",
    "states, actions, rewards, next_states, dones = train_q.dequeue_many(batch_size)\n",
    "q_close = train_q.close(cancel_pending_enqueues=True)\n",
    "\n",
    "\"\"\" Q-net and target Q-net \"\"\"\n",
    "with tf.variable_scope('qnet') as scope:\n",
    "    Qnet = QNet(num_states=env.num_states, num_actions=env.num_actions, name=scope.name)\n",
    "    qnet = Qnet(states)\n",
    "    qnet_explore = Qnet(state_holder_explore, reuse=True)\n",
    "    greedy_action = tf.argmax(qnet_explore, axis=1)[0]\n",
    "\n",
    "with tf.variable_scope('target_qnet') as scope:\n",
    "    Qnet_target = QNet(num_states=env.num_states, num_actions=env.num_actions, \\\n",
    "                       name=scope.name)\n",
    "    qnet_target = Qnet_target(next_states)\n",
    "    qnet_target_max = tf.reduce_max(qnet_target, axis=1, keepdims=True)\n",
    "\n",
    "\"\"\" Variables Copy Operation \"\"\"\n",
    "copy_ops = variable_copy(from_scope=Qnet.name, to_scope=Qnet_target.name)\n",
    "\n",
    "\"\"\" Q-target \"\"\"\n",
    "q_target = tf.stop_gradient(\n",
    "    (1.0 - tf.to_float(dones)) * (rewards + gamma * qnet_target_max) \\\n",
    "    + tf.to_float(dones) * rewards)\n",
    "\n",
    "\"\"\" Loss & Training Operations\"\"\"\n",
    "q_sa = tf.reduce_sum(qnet * tf.one_hot(actions, env.num_actions, dtype=tf.float32), \\\n",
    "                     axis=1, \\\n",
    "                     keepdims=True)\n",
    "q_loss = tf.reduce_mean(tf.square(q_sa - q_target))\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate=lr_rate)\n",
    "train_ops = opt.minimize(q_loss, \\\n",
    "                         var_list=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \\\n",
    "                                                    Qnet.name))\n",
    "\n",
    "\" Variable Initializer\"\n",
    "init_ops = tf.global_variables_initializer()\n",
    "\n",
    "\"\"\" Replay Memory\"\"\"\n",
    "replay_memory = deque(maxlen=memory_size)\n",
    "\n",
    "\n",
    "class SampleEnquer(threading.Thread):\n",
    "    def __init__(self, sess):\n",
    "        super(SampleEnquer, self).__init__()\n",
    "        self._sess = sess\n",
    "\n",
    "        self._stopEvent = threading.Event()\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            # Sample scenarios from replay-memory.\n",
    "            samples = random.sample(replay_memory, batch_size)\n",
    "\n",
    "            states_ = [sample.state for sample in samples]\n",
    "            actions_ = [sample.action for sample in samples]\n",
    "            rewards_ = [sample.reward for sample in samples]\n",
    "            next_states_ = [sample.next_state for sample in samples]\n",
    "            dones_ = [sample.done for sample in samples]\n",
    "\n",
    "            states = one_hot_encode(states_, env.num_states)\n",
    "            actions = one_hot_encode(actions_, env.num_actions)\n",
    "            actions = np.array(actions_, dtype=np.int32)\n",
    "            rewards = np.reshape(np.array(rewards_, dtype=np.float32), [-1, 1])\n",
    "            next_states = one_hot_encode(next_states_, env.num_states)\n",
    "            dones = np.reshape(np.array(dones_, dtype=np.float32), [-1, 1])\n",
    "\n",
    "            try:\n",
    "                sess.run(enqueue_op, feed_dict={state_holder: states,\n",
    "                                                action_holder: actions,\n",
    "                                                reward_holder: rewards,\n",
    "                                                next_state_holder: next_states,\n",
    "                                                done_holder: dones})\n",
    "            except Exception as ex:\n",
    "                break\n",
    "\n",
    "    def stop(self):\n",
    "        sess.run(q_close)\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init_ops)\n",
    "\n",
    "\"\"\" Burning Period \"\"\"\n",
    "logging.info('Initial Burning Period')\n",
    "for i in range(num_burning_episode):\n",
    "    \n",
    "    env.current_state, env.done = env.reset()\n",
    "    \n",
    "    while not env.done:\n",
    "        action = env.random_action() # this is random action\n",
    "        env.reward, next_state, env.done, _, _ = env.step(action)\n",
    "\n",
    "        sample = exp(state=env.current_state, \\\n",
    "                     action=action, \\\n",
    "                     reward=env.reward, \\\n",
    "                     next_state=next_state, \\\n",
    "                     done=env.done)\n",
    "        replay_memory.append(sample)\n",
    "\n",
    "        env.current_state = next_state\n",
    "\n",
    "\"\"\" Training \"\"\"\n",
    "logging.info('Training Start')\n",
    "train_step = 0\n",
    "cum_return_test = []\n",
    "step_history = []\n",
    "\n",
    "sample_enquer = SampleEnquer(sess)\n",
    "sample_enquer.start()\n",
    "\n",
    "for episode_num in range(max_episodes):\n",
    "    \n",
    "    # Reset Environment and Reset Cum. Reward\n",
    "    env.current_state, env.done = env.reset()\n",
    "        \n",
    "    learning_rate = 1. / ((episode_num * 0.1) + 1.)\n",
    "    epsilon = 1. / ((episode_num * 0.1) + 1.)\n",
    "\n",
    "    while not env.done:\n",
    "        \n",
    "        # Action Selection\n",
    "        if np.random.uniform(0.,1.) > epsilon:\n",
    "            action = sess.run(greedy_action,\n",
    "                              feed_dict={state_holder_explore: \\\n",
    "                                         one_hot_encode([env.current_state], \\\n",
    "                                                        env.num_states)})\n",
    "        else:\n",
    "            action = env.random_action() # random action\n",
    "        \n",
    "        env.reward, next_state, env.done, _, _ = env.step(action)\n",
    "\n",
    "        sample = exp(state=env.current_state, \\\n",
    "                     action=action, \\\n",
    "                     reward=env.reward, \\\n",
    "                     next_state=next_state, \\\n",
    "                     done=env.done)\n",
    "        replay_memory.append(sample)\n",
    "        \n",
    "        env.current_state = next_state\n",
    "\n",
    "        sess.run(train_ops, feed_dict={lr_rate: learning_rate})\n",
    "\n",
    "        train_step += 1\n",
    "\n",
    "        # Network Synchronization\n",
    "        if train_step % copy_period == 0:\n",
    "            sess.run(copy_ops)\n",
    "\n",
    "        # Terminal of Scenario.\n",
    "        if env.done:\n",
    "            if env.current_state == env.win_state:\n",
    "                step_history.append(1)\n",
    "            if env.current_state == env.lose_state:\n",
    "                step_history.append(0)\n",
    "            break\n",
    "\n",
    "    if (episode_num + 1) % 100 == 0:\n",
    "        logging.info('Episode  %d' % (episode_num + 1))\n",
    "\n",
    "    \"\"\" Test \"\"\"\n",
    "    if episode_num % test_period == 0:\n",
    "        env.current_state, env.done = env.reset()\n",
    "        cum_rwd = 0.0\n",
    "\n",
    "        while not env.done:\n",
    "            \n",
    "            # Action Selection\n",
    "            if np.random.uniform(0.,1.) > epsilon_test:\n",
    "                action = sess.run(greedy_action, \\\n",
    "                                  feed_dict={state_holder_explore: \\\n",
    "                                             one_hot_encode([env.current_state], \\\n",
    "                                                            env.num_states)})\n",
    "            else:\n",
    "                action = env.random_action() # random action\n",
    "                \n",
    "            env.reward, next_state, env.done, _, _ = env.step(action)\n",
    "            cum_rwd += env.reward\n",
    "            \n",
    "            if cum_rwd < -10.:\n",
    "                break\n",
    "\n",
    "            env.current_state = next_state\n",
    "\n",
    "        cum_return_test.append(cum_rwd)\n",
    "\n",
    "sample_enquer.stop()\n",
    "sample_enquer.join()\n",
    "\n",
    "fig = plt.figure(1)\n",
    "history = np.cumsum(step_history) / (np.arange(max_episodes) + 1)\n",
    "print(history[-1])\n",
    "plt.plot(history)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(2)\n",
    "plt.plot(np.arange(len(cum_return_test)) * test_period, cum_return_test)\n",
    "plt.xlabel('episode.')\n",
    "plt.ylabel('cum. reward')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN - tensorflow implementation\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import threading\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "from dqn_env import ENVIRONMENT\n",
    "from dqn_ops import one_hot_encode, variable_copy \n",
    "from dqn_q_net import QNet\n",
    "\n",
    "# this line is not needed in py file\n",
    "%matplotlib inline\n",
    "# this line is not needed in py file\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_random_seed(0)\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(message)s')\n",
    "\n",
    "\"\"\" Hyper Parameters \"\"\"\n",
    "gamma = 0.99\n",
    "max_episodes = 10000 #20000\n",
    "epsilon = 0.10\n",
    "memory_size = 1000\n",
    "num_burning_episode = 100\n",
    "batch_size = 32\n",
    "copy_period = 100\n",
    "test_period = 100\n",
    "epsilon_test = 0.00\n",
    "\n",
    "\"\"\" Environment \"\"\"\n",
    "env = ENVIRONMENT()\n",
    "# exp = namedtuple('experience', ['state', 'action', 'reward', 'next_state', 'done'])\n",
    "exp = namedtuple('experience', ['state', 'action', 'reward', 'next_state'])\n",
    "\n",
    "\" Train-Queue \"\n",
    "# train_q = tf.FIFOQueue(capacity=100,\n",
    "#                        dtypes=[tf.float32, tf.int32, tf.float32, tf.float32, tf.bool],\n",
    "#                        shapes=[env.num_states, [], 1, env.num_states, 1],\n",
    "#                        name='train_queue')\n",
    "train_q = tf.FIFOQueue(capacity=100,\n",
    "                       dtypes=[tf.float32, tf.int32, tf.float32, tf.float32],\n",
    "                       shapes=[env.num_states, [], 1, env.num_states],\n",
    "                       name='train_queue')\n",
    "\n",
    "\" Inputs Placeholder \"\n",
    "state_holder = tf.placeholder(tf.float32, [None, env.num_states], 'state_holder')\n",
    "action_holder = tf.placeholder(tf.int32, [None], 'action_holder')\n",
    "reward_holder = tf.placeholder(tf.float32, [None, 1], 'reward_holder')\n",
    "next_state_holder = tf.placeholder(tf.float32, [None, env.num_states], 'next_state_holder')\n",
    "done_holder = tf.placeholder(tf.bool, [None, 1], 'state_holder')\n",
    "lr_rate = tf.placeholder(dtype=tf.float32, shape=[], name='lr_rate')\n",
    "\n",
    "state_holder_explore = tf.placeholder(tf.float32, [None, env.num_states], \\\n",
    "                                      'state_holder_explore')\n",
    "\n",
    "\" Queue Ops \"\n",
    "# enqueue_op = train_q.enqueue_many([state_holder, \\\n",
    "#                                    action_holder, \\\n",
    "#                                    reward_holder, \\\n",
    "#                                    next_state_holder, \\\n",
    "#                                    done_holder])\n",
    "enqueue_op = train_q.enqueue_many([state_holder, \\\n",
    "                                   action_holder, \\\n",
    "                                   reward_holder, \\\n",
    "                                   next_state_holder])\n",
    "# states, actions, rewards, next_states, dones = train_q.dequeue_many(batch_size)\n",
    "states, actions, rewards, next_states = train_q.dequeue_many(batch_size)\n",
    "q_close = train_q.close(cancel_pending_enqueues=True)\n",
    "\n",
    "\"\"\" Q-net and target Q-net \"\"\"\n",
    "with tf.variable_scope('qnet') as scope:\n",
    "    Qnet = QNet(num_states=env.num_states, num_actions=env.num_actions, name=scope.name)\n",
    "    qnet = Qnet(states)\n",
    "    qnet_explore = Qnet(state_holder_explore, reuse=True)\n",
    "    greedy_action = tf.argmax(qnet_explore, axis=1)[0]\n",
    "\n",
    "with tf.variable_scope('target_qnet') as scope:\n",
    "    Qnet_target = QNet(num_states=env.num_states, num_actions=env.num_actions, \\\n",
    "                       name=scope.name)\n",
    "    qnet_target = Qnet_target(next_states)\n",
    "    qnet_target_max = tf.reduce_max(qnet_target, axis=1, keepdims=True)\n",
    "\n",
    "\"\"\" Variables Copy Operation \"\"\"\n",
    "copy_ops = variable_copy(from_scope=Qnet.name, to_scope=Qnet_target.name)\n",
    "\n",
    "\"\"\" Q-target \"\"\"\n",
    "# q_target = tf.stop_gradient(\n",
    "#     (1.0 - tf.to_float(dones)) * (rewards + gamma * qnet_target_max) \\\n",
    "#     + tf.to_float(dones) * rewards)\n",
    "q_target = tf.stop_gradient(rewards + gamma * qnet_target_max)\n",
    "\n",
    "\"\"\" Loss & Training Operations\"\"\"\n",
    "q_sa = tf.reduce_sum(qnet * tf.one_hot(actions, env.num_actions, dtype=tf.float32), \\\n",
    "                     axis=1, \\\n",
    "                     keepdims=True)\n",
    "q_loss = tf.reduce_mean(tf.square(q_sa - q_target))\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate=lr_rate)\n",
    "train_ops = opt.minimize(q_loss, \\\n",
    "                         var_list=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \\\n",
    "                                                    Qnet.name))\n",
    "\n",
    "\" Variable Initializer\"\n",
    "init_ops = tf.global_variables_initializer()\n",
    "\n",
    "\"\"\" Replay Memory\"\"\"\n",
    "replay_memory = deque(maxlen=memory_size)\n",
    "\n",
    "\n",
    "class SampleEnquer(threading.Thread):\n",
    "    def __init__(self, sess):\n",
    "        super(SampleEnquer, self).__init__()\n",
    "        self._sess = sess\n",
    "\n",
    "        self._stopEvent = threading.Event()\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            # Sample scenarios from replay-memory.\n",
    "            samples = random.sample(replay_memory, batch_size)\n",
    "\n",
    "            states_ = [sample.state for sample in samples]\n",
    "            actions_ = [sample.action for sample in samples]\n",
    "            rewards_ = [sample.reward for sample in samples]\n",
    "            next_states_ = [sample.next_state for sample in samples]\n",
    "            #dones_ = [sample.done for sample in samples]\n",
    "\n",
    "            states = one_hot_encode(states_, env.num_states)\n",
    "            # actions = one_hot_encode(actions_, env.num_action)\n",
    "            actions = np.array(actions_, dtype=np.int32)\n",
    "            rewards = np.reshape(np.array(rewards_, dtype=np.float32), [-1, 1])\n",
    "            next_states = one_hot_encode(next_states_, env.num_states)\n",
    "            #dones = np.reshape(np.array(dones_, dtype=np.float32), [-1, 1])\n",
    "\n",
    "            try:\n",
    "#                 sess.run(enqueue_op, feed_dict={state_holder: states,\n",
    "#                                                 action_holder: actions,\n",
    "#                                                 reward_holder: rewards,\n",
    "#                                                 next_state_holder: next_states,\n",
    "#                                                 done_holder: dones})\n",
    "                sess.run(enqueue_op, feed_dict={state_holder: states,\n",
    "                                                action_holder: actions,\n",
    "                                                reward_holder: rewards,\n",
    "                                                next_state_holder: next_states})\n",
    "            except Exception as ex:\n",
    "                break\n",
    "\n",
    "    def stop(self):\n",
    "        sess.run(q_close)\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init_ops)\n",
    "\n",
    "\"\"\" Burning Period \"\"\"\n",
    "logging.info('Initial Burning Period')\n",
    "for i in range(num_burning_episode):\n",
    "    \n",
    "    env.current_state, env.done = env.reset()\n",
    "    \n",
    "    while not env.done:\n",
    "        action = env.random_action() # this is random action\n",
    "        env.reward, next_state, env.done, _, _ = env.step(action)\n",
    "\n",
    "#         sample = exp(state=env.current_state, \\\n",
    "#                      action=action, \\\n",
    "#                      reward=env.reward, \\\n",
    "#                      next_state=next_state, \\\n",
    "#                      done=env.done)\n",
    "        sample = exp(state=env.current_state, \\\n",
    "                     action=action, \\\n",
    "                     reward=env.reward, \\\n",
    "                     next_state=next_state)\n",
    "        replay_memory.append(sample)\n",
    "\n",
    "        env.current_state = next_state\n",
    "\n",
    "\"\"\" Training \"\"\"\n",
    "logging.info('Training Start')\n",
    "train_step = 0\n",
    "cum_return_test = []\n",
    "step_history = []\n",
    "\n",
    "sample_enquer = SampleEnquer(sess)\n",
    "sample_enquer.start()\n",
    "\n",
    "for episode_num in range(max_episodes):\n",
    "    \n",
    "    # Reset Environment and Reset Cum. Reward\n",
    "    env.current_state, env.done = env.reset()\n",
    "        \n",
    "    learning_rate = 1. / ((episode_num * 0.1) + 1.)\n",
    "    epsilon = 1. / ((episode_num * 0.1) + 1.)\n",
    "\n",
    "    while not env.done:\n",
    "        \n",
    "        # Action Selection\n",
    "        if np.random.uniform(0.,1.) > epsilon:\n",
    "            action = sess.run(greedy_action,\n",
    "                              feed_dict={state_holder_explore: \\\n",
    "                                         one_hot_encode([env.current_state], \\\n",
    "                                                        env.num_states)})\n",
    "        else:\n",
    "            action = env.random_action() # random action\n",
    "        \n",
    "        env.reward, next_state, env.done, _, _ = env.step(action)\n",
    "\n",
    "#         sample = exp(state=env.current_state, \\\n",
    "#                      action=action, \\\n",
    "#                      reward=env.reward, \\\n",
    "#                      next_state=next_state, \\\n",
    "#                      done=env.done)\n",
    "        sample = exp(state=env.current_state, \\\n",
    "                     action=action, \\\n",
    "                     reward=env.reward, \\\n",
    "                     next_state=next_state)\n",
    "        replay_memory.append(sample)\n",
    "        \n",
    "        env.current_state = next_state\n",
    "\n",
    "        sess.run(train_ops, feed_dict={lr_rate: learning_rate})\n",
    "\n",
    "        train_step += 1\n",
    "\n",
    "        # Network Synchronization\n",
    "        if train_step % copy_period == 0:\n",
    "            sess.run(copy_ops)\n",
    "\n",
    "        # Terminal of Scenario.\n",
    "        if env.done:\n",
    "            if env.current_state == env.win_state:\n",
    "                step_history.append(1)\n",
    "            if env.current_state == env.lose_state:\n",
    "                step_history.append(0)\n",
    "            break\n",
    "\n",
    "    if (episode_num + 1) % 100 == 0:\n",
    "        logging.info('Episode  %d' % (episode_num + 1))\n",
    "\n",
    "    \"\"\" Test \"\"\"\n",
    "    if episode_num % test_period == 0:\n",
    "        env.current_state, env.done = env.reset()\n",
    "        cum_rwd = 0.0\n",
    "\n",
    "        while not env.done:\n",
    "            \n",
    "            # Action Selection\n",
    "            if np.random.uniform(0.,1.) > epsilon_test:\n",
    "                action = sess.run(greedy_action, \\\n",
    "                                  feed_dict={state_holder_explore: \\\n",
    "                                             one_hot_encode([env.current_state], \\\n",
    "                                                            env.num_states)})\n",
    "            else:\n",
    "                action = env.random_action() # random action\n",
    "                \n",
    "            env.reward, next_state, env.done, _, _ = env.step(action)\n",
    "            cum_rwd += env.reward\n",
    "            \n",
    "            if cum_rwd < -10.:\n",
    "                break\n",
    "\n",
    "            env.current_state = next_state\n",
    "\n",
    "        cum_return_test.append(cum_rwd)\n",
    "\n",
    "sample_enquer.stop()\n",
    "sample_enquer.join()\n",
    "\n",
    "fig = plt.figure(1)\n",
    "history = np.cumsum(step_history) / (np.arange(max_episodes) + 1)\n",
    "print(history[-1])\n",
    "plt.plot(history)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(2)\n",
    "plt.plot(np.arange(len(cum_return_test)) * test_period, cum_return_test)\n",
    "plt.xlabel('episode.')\n",
    "plt.ylabel('cum. reward')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercise\n",
    "\n",
    "- The above code is using the numpy package. Modify the code using the tensorflow instead.\n",
    "\n",
    "- The above code has ``Burning Period''. Comment out the burning period part of the code and modify the code so that it runs. State your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"img/Improvements since Nature DQN.png\" width=\"50%\" height=\"20%\"></div>\n",
    "\n",
    "http://icml.cc/2016/tutorials/deep_rl_tutorial.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Asynchronous Method\n",
    "\n",
    "최근에는 Asynchronous Method라는 방법으로 correlation을 없애줘서 Experience Replay를 대체한다고 한다. 간단히 Asynchronous Method를 설명하면 Thread를 통해서 여러개의 agent가 동시에 [state, action, reward, state’]를 수집한다. 그렇게 여러 agent가 동시에 수집한 데이터들은 서로 correlation이 없을 것이기 때문에 Experience Replay를 대체할 수 있으면서 더 빠르고 메모리도 절약할 수 있는 방법이라고 한다.\n",
    "\n",
    "http://www.phrgcm.com/blog/2016/08/17/deep-q-network/\n",
    "\n",
    "https://arxiv.org/pdf/1602.01783v2.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dueling DQN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\begin{array}{ccccccccc}\n",
    "Q(s,a)&=&V(s)&+&A(s,a)\\\\\n",
    "\\uparrow&&\\uparrow&&\\uparrow\\\\\n",
    "\\mbox{$Q$ function}&&\\mbox{value function}&&\\mbox{advantage function}\\\\\n",
    "\\end{array}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"img/1-N_t9I7MeejAoWlDuH1i7cw.png\" width=\"30%\" height=\"10%\"></div>\n",
    "\n",
    "https://medium.com/@awjuliani/simple-reinforcement-learning-with-tensorflow-part-4-deep-q-networks-and-beyond-8438a3e2b8df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# StarCraft II \n",
    "\n",
    "\n",
    "<div align=\"center\"><img src=\"img/StarCraft II.png\" width=\"100%\" height=\"10%\"></div>\n",
    "\n",
    "- DeepMind \n",
    "[StarCraft II 'mini games' for AI research](https://www.youtube.com/watch?time_continue=3&v=6L448yg0Sm0)\n",
    "[Trained and untrained agents play StarCraft II full 1vs1 game](https://www.youtube.com/watch?time_continue=2&v=WEOzide5XFc)\n",
    "[paper](https://arxiv.org/pdf/1708.04782.pdf)\n",
    "[local](http://localhost:8888/notebooks/Dropbox/Paper/1708.04782.pdf)\n",
    "[github](https://github.com/Blizzard/s2client-proto)\n",
    "\n",
    "- Siraj Raval \n",
    "[A Guide to DeepMind's StarCraft AI Environment](https://www.youtube.com/watch?v=URWXG5jRB-A)\n",
    "\n",
    "- Two Minute Papers #182 \n",
    "[DeepMind Publishes StarCraft II Learning Environment](https://www.youtube.com/watch?v=St5lxIxYGkI)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
