{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">[Policy Gradient Methods for Reinforcement Learning with Function Approximation (2000)](http://localhost:8888/notebooks/Dropbox/Paper/1713-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf)\n",
    "</font>\n",
    "<font size=\"1\">\n",
    "    [Simulation-Based  Optimization  of Markov Reward Processes (2001)](http://localhost:8888/notebooks/Dropbox/Paper/J083-01-mar-MDP.pdf)\n",
    "</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $V^\\pi$ and $Q^\\pi$\n",
    "$$\n",
    "V^\\pi(s)=\\sum_a\\pi(s,a)Q^\\pi(s,a)\n",
    "$$\n",
    "$$\n",
    "Q^\\pi(s,a)={\\cal R}^a_s+\\sum_{s'}\\gamma{\\cal P}^a_{ss'}V^\\pi(s')\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Measure of Policy\n",
    "$$\n",
    "\\rho=\\rho(\\pi)=\\mathbb{E}_{\\mathbb{P}_0}^\\pi\\sum_{t=0}^\\infty\\gamma^t r_t\n",
    "=\\sum_sV^\\pi(s)\\mathbb{P}_0(s)\n",
    "\\quad\n",
    "\\mbox{$\\mathbb{P}_0$ initial distribution}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Gradient Thoerem\n",
    "$$\n",
    "\\frac{\\partial\\rho}{\\partial\\theta}\n",
    "=\\sum_{s}\\sum_{a}d_{s}^\\pi\\pi(s,a)\\frac{\\partial\\log\\pi(s,a)}{\\partial\\theta}Q^\\pi(s,a)\n",
    "\\approx\\frac{1}{1-\\gamma}\\mathbb{E}_\\pi\\left[\\frac{\\partial\\log\\pi}{\\partial\\theta}Q^\\pi\\right]\n",
    "$$\n",
    "where\n",
    "$$\n",
    "d_{ss'}^\\pi:=\\sum_{t=0}^\\infty\\gamma^t\\mathbb{P}_{ss'}^\\pi(t)\n",
    "$$\n",
    "$$\n",
    "d_{s'}^\\pi:=\\sum_s d_{ss'}^\\pi \\mathbb{P}_0(s)\n",
    "\\quad\n",
    "\\mbox{$\\mathbb{P}_0$ initial distribution}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Idea of Proof - Recursion\n",
    "$$\\begin{array}{lll}\n",
    "\\frac{\\partial V^\\pi(s)}{\\partial\\theta}&=&\\frac{\\partial}{\\partial\\theta}\\sum_a\\pi(s,a)Q^\\pi(s,a)\\\\\n",
    "&=&\\sum_a\\frac{\\partial\\pi(s,a)}{\\partial\\theta}Q^\\pi(s,a)+\\sum_a\\pi(s,a)\\frac{\\partial Q^\\pi(s,a)}{\\partial\\theta}\\\\\n",
    "&=&\\sum_a\\frac{\\partial\\pi(s,a)}{\\partial\\theta}Q^\\pi(s,a)+\\sum_a\\pi(s,a)\\frac{\\partial }{\\partial\\theta}\\left[{\\cal R}^a_s+\\sum_{s'}\\gamma{\\cal P}^a_{ss'}V^\\pi(s')\\right]\\\\\n",
    "&=&\\sum_a\\frac{\\partial\\pi(s,a)}{\\partial\\theta}Q^\\pi(s,a)+\\sum_a\\pi(s,a)\\sum_{s'}\\gamma{\\cal P}^a_{ss'}\\frac{\\partial V^\\pi(s')}{\\partial\\theta}\\\\\n",
    "&=&\\sum_{s'}\\sum_{a'}\\left(\\sum_{t=0}^0\\gamma^t\\mathbb{P}_{ss'}^\\pi(t)\\right)\\frac{\\partial\\pi(s',a')}{\\partial\\theta}Q^\\pi(s',a')+\\sum_{s'}\\gamma\\mathbb{P}_{ss'}^\\pi(1)\\frac{\\partial V^\\pi(s')}{\\partial\\theta}\\\\\n",
    "&=&\\sum_{s'}\\sum_{a'}\\left(\\sum_{t=0}^1\\gamma^t\\mathbb{P}_{ss'}^\\pi(t)\\right)\\frac{\\partial\\pi(s',a')}{\\partial\\theta}Q^\\pi(s',a')+\\sum_{s'}\\gamma^2\\mathbb{P}_{ss'}^\\pi(2)\\frac{\\partial V^\\pi(s')}{\\partial\\theta}\\\\\n",
    "&=&\\sum_{s'}\\sum_{a'}\\left(\\sum_{t=0}^2\\gamma^t\\mathbb{P}_{ss'}^\\pi(t)\\right)\\frac{\\partial\\pi(s',a')}{\\partial\\theta}Q^\\pi(s',a')+\\sum_{s'}\\gamma^3\\mathbb{P}_{ss'}^\\pi(3)\\frac{\\partial V^\\pi(s')}{\\partial\\theta}\\\\\n",
    "&=&\\sum_{s'}\\sum_{a'}\\left(\\sum_{t=0}^\\infty\\gamma^t\\mathbb{P}_{ss'}^\\pi(t)\\right)\\frac{\\partial\\pi(s',a')}{\\partial\\theta}Q^\\pi(s',a')\\\\\n",
    "&=&\\sum_{s'}\\sum_{a'}d_{ss'}^\\pi\\frac{\\partial\\pi(s',a')}{\\partial\\theta}Q^\\pi(s',a')\\\\\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Touch - Averaging\n",
    "$$\\begin{array}{lll}\n",
    "\\frac{\\partial\\rho}{\\partial\\theta}\n",
    "&=&\\sum_s\\frac{\\partial V^\\pi(s)}{\\partial\\theta}\\mathbb{P}_0(s)\\\\\n",
    "&=&\\sum_{s'}\\sum_{a'}\\left(\\sum_s d_{ss'}^\\pi \\mathbb{P}_0(s)\\right)\\frac{\\partial\\pi(s',a')}{\\partial\\theta}Q^\\pi(s',a')\\\\\n",
    "&=&\\sum_{s'}\\sum_{a'}d_{s'}^\\pi\\frac{\\partial\\pi(s',a')}{\\partial\\theta}Q^\\pi(s',a')\\\\\n",
    "&=&\\sum_{s'}\\sum_{a'}d_{s'}^\\pi\\pi(s',a')\\frac{\\frac{\\partial\\pi(s',a')}{\\partial\\theta}}{\\pi(s',a')}Q^\\pi(s',a')\\\\\n",
    "&=&\\sum_{s'}\\sum_{a'}d_{s'}^\\pi\\pi(s',a')\\frac{\\partial\\log\\pi(s',a')}{\\partial\\theta}Q^\\pi(s',a')\\\\\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximation. \n",
    "\n",
    "If the initial distribution $\\mathbb{P}_0$ is the stationary distribution of MDP with policy $\\pi$,\n",
    "$$\n",
    "d_{s'}^\\pi\n",
    "=\\sum_s d_{ss'}^\\pi \\mathbb{P}_0(s)\n",
    "=\\sum_s\\sum_{t=0}^\\infty\\gamma^t\\mathbb{P}_{ss'}^\\pi(t)\\mathbb{P}_0(s)\n",
    "=\\sum_{t=0}^\\infty\\gamma^t\\mathbb{P}_0(s')\n",
    "=\\frac{1}{1-\\gamma}\\mathbb{P}_0(s')\n",
    "$$\n",
    "$$\\begin{array}{lll}\n",
    "\\frac{\\partial\\rho}{\\partial\\theta}\n",
    "&=&\\frac{1}{1-\\gamma}\\sum_{s'}\\sum_{a'}\\mathbb{P}_0(s')\\pi(s',a')\\frac{\\partial\\log\\pi(s',a')}{\\partial\\theta}Q^\\pi(s',a')\\\\\n",
    "&=&\\frac{1}{1-\\gamma}\\mathbb{E}_\\pi\\left[\\frac{\\partial\\log\\pi}{\\partial\\theta}Q^\\pi\\right]\\\\\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advantage Version. \n",
    "\n",
    "Above identities and approximations still holds even if we replace $Q^\\pi$ with\n",
    "$A^\\pi=Q^\\pi-V^\\pi$ since\n",
    "$$\\begin{array}{lll}\n",
    "\\sum_{s'}\\sum_{a'}d_{ss'}^\\pi\\frac{\\partial\\pi(s',a')}{\\partial\\theta}V^\\pi(s')\n",
    "&=&\n",
    "\\sum_{s'}d_{ss'}^\\pi V^\\pi(s')\\sum_{a'}\\frac{\\partial\\pi(s',a')}{\\partial\\theta}\\\\\n",
    "&=&\n",
    "\\sum_{s'}d_{ss'}^\\pi V^\\pi(s')\\frac{\\partial}{\\partial\\theta}\\sum_{a'}\\pi(s',a')\\\\\n",
    "&=&\n",
    "\\sum_{s'}d_{ss'}^\\pi V^\\pi(s')\\frac{\\partial}{\\partial\\theta}1\\\\\n",
    "&=&0\\\\\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial\\rho}{\\partial\\theta}\n",
    "=\\sum_{s}\\sum_{a}d_{s}^\\pi\\pi(s,a)\\frac{\\partial\\log\\pi(s,a)}{\\partial\\theta}A^\\pi(s,a)\n",
    "\\approx\\frac{1}{1-\\gamma}\\mathbb{E}_\\pi\\left[\\frac{\\partial\\log\\pi}{\\partial\\theta}A^\\pi\\right]\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
